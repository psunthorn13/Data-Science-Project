{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task1_31258301",
      "provenance": [],
      "collapsed_sections": [
        "U2NdpSB_6KpA",
        "66kJqbPo6TOF",
        "kfQVK-Z_TEWg",
        "ym6UpIFoYbFy",
        "3ASuyuTMKLp4"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21lKPjFg5WOq"
      },
      "source": [
        "# FIT5196 Assessment 1 Task 1\n",
        "#### Student Name: Pichaphop Sunthornjittanon\n",
        "#### Student ID: 31258301\n",
        "\n",
        "Date: 31/08/21\n",
        " ##############################\n",
        "\n",
        "\n",
        "Environment: Python 3.7.11 and Google Collab\n",
        "\n",
        "Libraries used:\n",
        "* re (Regular expression)\n",
        "* os (Operating System)\n",
        "\n",
        "\n",
        "## 1. Introduction\n",
        "This assessment touches the very first step of analyzing textual data, i.e., extracting data\n",
        "from semi-structured text files. Each\n",
        "text file contains information about the tweets, i.e., ‚Äúuser name‚Äù, ‚Äúuser code‚Äù, ‚Äúuser\n",
        "description‚Äù, ‚Äúnumber of followers‚Äù, ‚Äúwhether or not the user account is verified‚Äù, ‚Äúdate\n",
        "of the tweet‚Äù, and the ‚Äútweet text‚Äù. Your task is to extract the data from the text file and\n",
        "transform the data into a XML format with the following elements:\n",
        "1. users: this tag wraps all the users\n",
        "2. user: this tag wraps all the tweets from a particular user and keeps the meta data for\n",
        "each user such as number of followers, verified or not, user description etc. If a user has\n",
        "multiple tweets, the meta data of the latest tweet (i.e., the tweet with the most\n",
        "recent date) must be used.\n",
        "3. Tweets: wraps all the tweets of a specific user\n",
        "4. tweet: for each user, this tag represents the text of the user tweet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2NdpSB_6KpA"
      },
      "source": [
        "## 2.  Importing libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYywWWzz6M0j"
      },
      "source": [
        "# Import required libraries\n",
        "\n",
        "# Use for Regular Expression\n",
        "import re\n",
        "\n",
        "# Use for Operating System\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66kJqbPo6TOF"
      },
      "source": [
        "## 3. Examining and loading data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nUUTlgLPDCk"
      },
      "source": [
        "In this section, we loaded and roughly explored the file from google drive with the file name 31258301_task1_input.txt, which will be further processed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVFGtuku6Cpd",
        "outputId": "3d0d69aa-69a1-4eb7-ec1e-aa35712a4a01"
      },
      "source": [
        "# Mount Google Drive in the colab environment\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhi-QbJ57JID"
      },
      "source": [
        "# Read the whole file\n",
        "with open('/content/drive/Shareddrives/FIT5196-s2-2021-tutorials/Assessment 1/Task1 datasets/31258301_task1_input.txt','r') as infile:\n",
        "    text = infile.read()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzWVPYbgPtNb",
        "outputId": "a8c9ab14-9917-4f9f-d56f-582919551973"
      },
      "source": [
        "# print first 20 lines of the file\n",
        "with open('/content/drive/Shareddrives/FIT5196-s2-2021-tutorials/Assessment 1/Task1 datasets/31258301_task1_input.txt','r') as infile:\n",
        "    print('\\n'.join([infile.readline().strip() for i in range(0, 20)])) "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "$username.: LIFE TOKEN HOLDERS\n",
            "$user_code.: 100000001\n",
            "$udesc.: Every 40 seconds someone commits suicide.\n",
            "‚Äç\n",
            "Life Token is a¬†charity-orientated¬†token on the¬†Binance Smart Chain. Our goal is to¬†aid Suicide Prevention charities\n",
            "$followerNo.: 6769.0 $verified?.: False $tweet_date.: 2021-02-10 23:58:48\n",
            "$tweet.: üòé Today, that's this #Thursday, we will do a \"üé¨ Take 2\" with our friend @LeoWandersleb, #Btc #wallet #security expe‚Ä¶ https://t.co/go6aDgRml5\n",
            "$username.: Mehidi Hasan\n",
            "$user_code.: 100030713\n",
            "$tweet_date.: 2021-07-05 16:46:47\n",
            "$tweet_text.: @IoLunaland project is presented by a competent team that has good potential for the implementation of the objectives. The key to the success of this project\n",
            "#presale #blockchain #cryptotrading #investing #cryptocurrency #bitcoin #trading #altcoin #cryptonews\n",
            "$verified_user?.: False $No. followers.: 2022.0 $user_desc.: nan\n",
            "$user_name.: conor prunty\n",
            "$user_code.: 100052719\n",
            "$user_desc.: Shit is about to go down when you see ‚Äòach, go tobann...‚Äô\n",
            "$followerNo.: 18.0 $verified?.: False $tweet_date.: 2021-06-22 04:41:08\n",
            "$tweet_text.: @SPHINX_BSC A good project with a great team\n",
            "@bscgem_early @FarmWerewolf @biswap_official\n",
            "0xD4D897aB41ebEFFBB8b4441869F6C126765f997B\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUjEvKaLuqEf"
      },
      "source": [
        "# Read the sample input file\n",
        "# with open('/content/sample_input.txt','r') as infile:\n",
        "#     text = infile.read()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfQVK-Z_TEWg"
      },
      "source": [
        "## 4. Extracting data using regular expression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCLF1U-J8TVk"
      },
      "source": [
        "In this section, we want to use regular expression to extract following data including user name, user code, user description, number of followers, whether or not the user account is verified, date of tweet and tweet text from the given text file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soHClbyOUnhM"
      },
      "source": [
        "Regular Expression Explaination\n",
        "\n",
        "- We use re.findall function to write regular expression and extract text,which match the specified pattern returning into list of texts\n",
        "- r\" some regular expression\" is used as a raw string to suppress actual meaning of escape characters, which help the code to be more readable\n",
        "- The pattern of extracted data is $(field name) : (extracted data)\n",
        "- Each attribute may have different field name such as user_name and uname\n",
        "- Some fields consist of multiple line data, so we use flags = DOTALL in order to make '.' special character capture everything including new line\n",
        "- (?:) is used for matching the pattern, but not captureing of the term in the blacket, while () is used for matching and capturing \n",
        "\n",
        "\n",
        "In this following section, each regular expression logic is explained below\n",
        "\n",
        "1. user_name - the username data was followed by the field name that start with $u and consist of the word 'name' following by ' .: '. Therefore, all texts were captured after the field name until the end of the lines.  \n",
        "\n",
        "2. user_code - the user code data was followed by the field name that start with $u and consist of the word 'code' following by ' .: ', which has 9 digits. Therefore, 9 digit numbers after the field name were captured.\n",
        "\n",
        "3. user_description - the user description data was followed by the field name that start with $u and consist of the word 'desc' following by ' .: '. User description can be in multiple line so we use flags = re.DOTALL that make '.' special characters capture everything including new line until the condition is met, which is the new the field username or number of followers. \n",
        "\n",
        "4. number_of_followers - the number of followers data was followed by the field name that consists of the word 'follower' and end by ' .: '. Therefore, all texts were captured after the field name until the end of the lines or finding the character \\$.  \n",
        "\n",
        "5. verified - the verification data was followed by the field name that consists of the word 'verif' and end by ' .: '. Therefore, all texts were captured after the field name until the end of the lines or finding the character \\$.  \n",
        "\n",
        "6. date of the tweet - the date of the tweet was followed by the field name that starts with the word '$tweet_date' and ends by ' .: '. Therefore, all texts were captured after the field name until the end of the lines or finding the character \\$.  \n",
        "\n",
        "7. tweet text - the field tweet text always follow by tweet date, but before username or verfied fields. So we capture the text between these two fields using dotall flag. Moreover, the tweet text is in the last field in the text so we include the patern of the lastest tweet and combind to not latest tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN8oY4DUTQCX"
      },
      "source": [
        "### 1.Regular expression to extract user_name ###\n",
        "user_name = re.findall(r\"(?:\\$u.*name\\.: )(.*)\",text)\n",
        "\n",
        "### 2.Regular expression to extract user_code ###\n",
        "user_code = re.findall(r'(?:\\$u.*code\\.: )(\\d{9})',text)\n",
        "\n",
        "### 3.Regular expression to extract user_decription ###\n",
        "user_description = re.findall(r'\\$u.*?desc.*?\\.: (.*?)(?:\\n)(?:\\$u.*?name\\.:|\\$follower.*?\\.: |\\$No.*?\\.)',text,flags= re.DOTALL)\n",
        "\n",
        "### 4.Regular expression to extract number of followers ###\n",
        "number_of_followers = re.findall(r'follower.*?\\.: (.*?) (?:\\$|\\n)',text)\n",
        "\n",
        "### 5.Regular expression to extract verified ###\n",
        "verified = re.findall('verif.*?\\.: (.*?) (?:\\$|\\n)',text)\n",
        "\n",
        "### 6.Regular expression to extract date_of_the_tweet ###\n",
        "date_of_the_tweet = re.findall('\\$tweet_date.*?\\.: (.*?)(?:\\$|\\n)', text)\n",
        "\n",
        "### 7.Regular expression to extract tweet text\n",
        "tweet_not_last = re.findall('\\$tweet_date.*?\\.: (?:.*?)(?:\\$|\\n)\\$.*?.: (.*?)(?:\\n)(?:\\$u.*?name\\.: |\\$verif.*?\\.:)', text,flags= re.DOTALL) \n",
        "tweet_last = re.findall('(?:\\$tweet_date.*?\\.: (?:.*?)(?:\\$|\\n)\\$.*.: (.*))', text,flags= re.DOTALL) \n",
        "tweet_last = list(map(lambda x: x.strip('\\n'),tweet_last))\n",
        "tweet = tweet_not_last +  tweet_last\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uep6Q1f6x4Pq",
        "outputId": "a2122ca4-defc-432a-dc2a-9f33997e4787"
      },
      "source": [
        "## Check length of each field list\n",
        "\n",
        "# user_name\n",
        "print('The length of user name list is ',len(user_name))\n",
        "\n",
        "# user_code\n",
        "print('The length of user code list is ',len(user_code))\n",
        "\n",
        "# user_description\n",
        "print('The length of user description list is ',len(user_description))\n",
        "\n",
        "# number_of_followers\n",
        "print('The length of number of followers list is ',len(number_of_followers))\n",
        "\n",
        "# verified\n",
        "print('The length of verified list is ',len(verified))\n",
        "\n",
        "# date_of_the_tweet\n",
        "print('The length of date of the tweet list is ',len(date_of_the_tweet))\n",
        "\n",
        "# tweet\n",
        "print('The length of tweet list is ',len(tweet))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of user name list is  12022\n",
            "The length of user code list is  12022\n",
            "The length of user description list is  12022\n",
            "The length of number of followers list is  12022\n",
            "The length of verified list is  12022\n",
            "The length of date of the tweet list is  12022\n",
            "The length of tweet list is  12022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym6UpIFoYbFy"
      },
      "source": [
        "## 5. Handling XML Special Characters "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKJiKv-QcYgo"
      },
      "source": [
        "Since we want to generate XML file as an output by extracting data from the given text file,  we need to deal with texts that contain XML special characters ,namely &amp;, &quot; ,&apos;,&gt;,&lt; by replacing them with \\&amp; , \\&quot; , \\&apos; ,\\&gt; ,\\&lt;. By doing that, the handle_XML_char is defined which replace XML special characters. After that, Map is used to map handle_XML_char to all field lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWkgXrExZFNU"
      },
      "source": [
        "# Define function that replace XML special characters \n",
        "def handle_XML_char(x) :\n",
        "  return x.replace('&','&amp;').replace('\"','&quot;').replace(\"'\",'&apos;').replace('>','&gt;').replace('<','&lt;')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVSY_uC4Z7rX"
      },
      "source": [
        "# Map the handle_XML_char function to all fields\n",
        "user_name = list(map(handle_XML_char,user_name))\n",
        "user_code = list(map(handle_XML_char,user_code))\n",
        "user_description = list(map(handle_XML_char,user_description))\n",
        "number_of_followers = list(map(handle_XML_char,number_of_followers))\n",
        "verified = list(map(handle_XML_char,verified))\n",
        "date_of_the_tweet = list(map(handle_XML_char,date_of_the_tweet))\n",
        "tweet = list(map(handle_XML_char,tweet))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ASuyuTMKLp4"
      },
      "source": [
        "##6. Creating  placeholders for metadata, tweet data and user number"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sASiDPN4fJDl"
      },
      "source": [
        "In this section, we aim to create 3 placeholders by utilising list and dictionary data structure \n",
        "\n",
        "**1.metadata** \n",
        "(user_name, number_of_followers,verified,latest_tweet_date)\n",
        "\n",
        "We use nested dictionary to place metadata inside since when the data is iterated, it can check at the existing key and latest tweet date to design whether to update meta data or not.\n",
        "\n",
        "This data is updated at most recent tweet date and is used user_no as a key in the main dictionary with the attributes as keys in sub-dictionaries\n",
        "\n",
        "*The example of the meta data format is shown belown*\n",
        "\n",
        "\n",
        "{\n",
        "\n",
        "**'100000001'**: \n",
        "\n",
        "{'latest_tweet_date': '2021-07-05 16:52:10',\n",
        "\n",
        "  'number_of_followers': '7449.0',\n",
        "\n",
        "  'user_description': 'Every 40 seconds someone commits suicide.\\n\\u200d\\nLife Token is a\\xa0charity-orientated\\xa0token on the\\xa0Binance Smart Chain. Our goal is to\\xa0aid Suicide Prevention charities',\n",
        "\n",
        "  'user_name': 'LIFE TOKEN HOLDERS',\n",
        "\n",
        "  'verified': 'False'},\n",
        "\n",
        " **'100030713':** {'latest_tweet_date': '2021-07-05 16:46:47',\n",
        "\n",
        "  'number_of_followers': '2022.0',\n",
        "\n",
        "  'user_description': 'nan',\n",
        "\n",
        "  'user_name': 'Mehidi Hasan',\n",
        "  \n",
        "  'verified': 'False'}\n",
        "\n",
        "}\n",
        "\n",
        "**2. Tweet data**\n",
        "\n",
        "We use dictionary that contains list of tweet data since in each iteration, we can  add more user_id and tweet text if the existing dictionary does not contain that data. However,if the the user_id is already existed, append the tweet data in the list.\n",
        "\n",
        "*The example of the tweet data format is shown belown*\n",
        "\n",
        "{\n",
        "\n",
        "**'100001281'**: ['#CenturyMarketNews on #Cryptocurrency: 7/7\\nThings could get even more exciting should the upcoming #SEC verdict res‚Ä¶ https://t.co/AUt9NOd6Bu'],\n",
        "\n",
        "\n",
        " **'100013247'**: [\n",
        "   \n",
        "   '[NEW] Coinbase Announces First Quarter 2021 Estimated Results : Verified Users of 56M, Trading Volume of $335B, Tot‚Ä¶ https://t.co/qxT4zfRVrR',\n",
        "  \n",
        "  '[NEW] What&apos;s the average holdings of a r/CryptoCurrency user? Share your portfolio value anonymously... +‚Ä¶ https://t.co/XHW6lCXw04',\n",
        " \n",
        "  '[NEW] Which are the most delusional crypto supporters, in your opinion + https://t.co/LNthwnpDhe #bitcoin #btc #cryptocurrency #crypto #blockchain']\n",
        "\n",
        "}\n",
        "\n",
        "**3. User number**\n",
        "To maintain the order of users, we create the list of user_id that append everytime in each iteration if the user is not in the list.\n",
        "\n",
        "*The example of the user number format is shown belown*\n",
        "\n",
        "['100000001',\n",
        " '100030713',\n",
        " '100052719',\n",
        " '100033219']\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAzgyfr8ny8S"
      },
      "source": [
        "# Initialise empty dictionary\n",
        "user_dict = dict()\n",
        "tweet_dict = dict()\n",
        "user_no_list = list()\n",
        "\n",
        "### For any data point in the tweet data ###\n",
        "for no_user in range(0,len(user_name)):\n",
        "\n",
        "  ## 1.If user is in the list, ##\n",
        "  if user_code[no_user] in user_dict.keys():\n",
        "\n",
        "    # Extract the specific user data in dictionary\n",
        "    old_user_data = user_dict[user_code[no_user]]\n",
        "\n",
        "    # Pull only date of the tweet of existing data\n",
        "    old_user_latest_tweet_date = old_user_data['latest_tweet_date']\n",
        "\n",
        "    # Look at date of the tweet of new data\n",
        "    new_user_tweet_date = date_of_the_tweet[no_user]\n",
        "    \n",
        "    # check if date of tweet is not a recent one\n",
        "    if old_user_latest_tweet_date > date_of_the_tweet[no_user] :\n",
        "\n",
        "      # Chcek \n",
        "      # print('usercode',user_code[no_user])\n",
        "      # print('old data',old_user_latest_tweet_date)\n",
        "      # print('new data',new_user_tweet_date)\n",
        "      \n",
        "      # Append tweet data into tweet dict in specific usercode\n",
        "      tweet_dict[user_code[no_user]].append(tweet [no_user])\n",
        "\n",
        "\n",
        "      # Not update meta data\n",
        "      continue\n",
        "\n",
        "  \n",
        "  ## 2.If the user is not in the list, ##\n",
        "  else :\n",
        "\n",
        "    # add the user in the user_no_list\n",
        "    user_no_list.append(user_code[no_user])\n",
        "\n",
        "    # Create new key (usercode) in tweet dictionary with value of empty list\n",
        "    tweet_dict[user_code[no_user]] = []\n",
        "\n",
        "  ## After that ##\n",
        "  # Add/update meta data\n",
        "  user_dict[user_code[no_user]] = {'user_name' : user_name[no_user],\n",
        "                                  'user_description' :user_description[no_user],\n",
        "                                  'number_of_followers' :number_of_followers[no_user],\n",
        "                                  'verified' :verified[no_user],\n",
        "                                  'latest_tweet_date' :date_of_the_tweet[no_user]\n",
        "  }\n",
        "\n",
        "  # Append tweet data into tweet dict in specific usercode\n",
        "  tweet_dict[user_code[no_user]].append(tweet [no_user])\n",
        "\n",
        "\n",
        "    \n",
        "    \n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmp8aCLJXU2z",
        "outputId": "7fcc6340-3dd9-458c-aef0-123bd46935d4"
      },
      "source": [
        "# Check the length of 3 placeholders\n",
        "print('Lenght of user dict is ', len(user_dict)) \n",
        "print('Lenght of tweet dict is ', len(tweet_dict)) \n",
        "print('Lenght of user no list is ', len(user_no_list)) \n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lenght of user dict is  7318\n",
            "Lenght of tweet dict is  7318\n",
            "Lenght of user no list is  7318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvm2YztwMa7K"
      },
      "source": [
        "##7. Writing XML file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8B5FwTdPbd7"
      },
      "source": [
        "The following code generates the final output, which is in XML format by opening write mode and name the file to 31258301.xml. The rest of the code uses for loop to write the given xml with data that can be extracted from metadata and tweet data dictionaries from the previous section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fREktOVUUkYr"
      },
      "source": [
        "# Write XML file\n",
        "\n",
        "with open('31258301.xml','w') as file :\n",
        "\n",
        "  file.write('<users>')\n",
        "\n",
        "  for user_no in user_no_list:\n",
        "    file.write('<user name=\"'+user_dict[user_no]['user_name']+'\">')\n",
        "    file.write('<verified_user>'+user_dict[user_no]['verified']+'</verified_user>')\n",
        "    file.write('<user_description>'+user_dict[user_no]['user_description']+'</user_description>')\n",
        "    file.write('<no_followers>'+user_dict[user_no]['number_of_followers']+'</no_followers>')\n",
        "    file.write('<tweets>')\n",
        "    for index in range(len(tweet_dict[user_no])):\n",
        "      file.write('<tweet>'+tweet_dict[user_no][index]+'</tweet>') \n",
        "    file.write('</tweets>')\n",
        "    file.write('</user>')\n",
        "  file.write('</users>')\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6No51nZ0nRy"
      },
      "source": [
        "##Summary\n",
        "\n",
        "In this assignment, we performed several steps to approach the problems and obtained the final result as the xml file name 31258301.xml. The steps included\n",
        "\n",
        "1. Introduction - Understand the requirement of this assignment\n",
        "2. Importing libraries -Import re and os libraries (only two are allowed)\n",
        "3. Examining and loading data - Load data from the given text file\n",
        "4. Extracting data using regular expression -Use regular expression to find the pattern and extract data from the text\n",
        "5. Handling XML Special Characters - Replace special characeters\n",
        "6. Creating placeholders for metadata, tweet data and user number - Create format of the data that will use for loop in the writing XML file part\n",
        "7. Writing XML file - Generate the final output 31258301.xml"
      ]
    }
  ]
}